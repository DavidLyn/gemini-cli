# Gemini工具使用提示工程深度分析

您好，这是一个非常深入的好问题。由于直接发送给您的分析内容屡次失败，我将完整的分析写入此文件，以确保您能收到。

我们来详细拆解一下`gemini/core`中围绕工具使用的这套精妙的“提示-决策-执行-响应”流程。这个过程可以清晰地分为三个阶段：

### 1. 如何为“工具使用”构造提示词？

当一个任务可能需要使用工具时，`gemini/core`构造提示词的方式是在我们之前讨论的“基础对话提示”上，**动态地附加一个“工具清单”**。

*   **基础提示**: 包含了`getCoreSystemPrompt()`返回的“行为手册”、完整的对话历史、以及用户当前的问题。
*   **附加的“工具清单”**:
    *   系统会调用`ToolRegistry`服务，获取当前所有已注册工具的详细“功能声明”（`FunctionDeclaration`）。
    *   这份声明就像一份详细的“工具说明书”，它会被格式化后附加到提示的末尾。每一份说明书都包含：
        1.  **`name`**: 工具的唯一标识符，例如 `read_file`。
        2.  **`description`**: 对工具功能的详细文字描述，例如“读取指定文件的内容，支持文本、图片和PDF”。这部分是写给大模型看的，让它能理解每个工具的用途。
        3.  **`parameters`**: 一个JSON Schema对象，精确定义了该工具需要哪些参数，以及每个参数的类型、描述和是否必需。例如，`read_file`工具的参数定义会指明它需要一个名为`absolute_path`的字符串参数。

通过这种方式，大模型在一次调用中就同时接收到了**用户的目标**（来自对话历史和问题）和**它能使用的全部手段**（来自这份详细的工具清单）。

### 2. 如何根据大模型返回值决定调用哪个工具？

这里的核心是，大模型的返回值**不是自然语言，而是一个结构化的指令**。

*   **返回`functionCall`对象**: 当大模型分析完带有工具清单的提示后，如果它判断出需要使用某个工具来回答用户的问题，它的返回内容不会是“好的，我将为您读取文件”，而是一个标准的、名为`functionCall`的JSON对象。
*   **`functionCall`的结构**: 这个对象包含了执行工具所需的一切信息，基本结构如下：
    ```json
    {
      "name": "read_file",
      "arguments": {
        "absolute_path": "/path/to/some/file.txt",
        "offset": 10,
        "limit": 50
      }
    }
    ```
*   **系统的解析与执行**: `gemini/core`的客户端（`GeminiClient`）在接收到这个`functionCall`对象后，就会像执行程序一样去解析它：
    1.  读取`name`字段，得知需要调用名为`read_file`的工具。
    2.  读取`arguments`字段，获得一个包含所有参数名和值的对象。
    3.  然后，它会在本地调用`ToolRegistry`中注册的`read_file`工具的执行逻辑，并将这些参数传递进去。

所以，整个决策过程完全由大模型自主完成，它通过返回一个标准化的`functionCall`对象，向`gemini/core`系统下达一个清晰、无歧义的执行指令。

### 3. 如何根据工具调用结果构造最终回答？

这是一个优雅的**“两步走”反馈循环**，目的是让最终的回答更智能、更人性化。

1.  **第一步：将“原始结果”反馈给大模型**
    *   当`gemini/core`在本地执行完工具后，会得到一个“原始结果”（可能是文件内容、命令行的输出、或是一个错误信息）。
    *   系统不会直接把这个原始结果展示给用户，而是会将其包装成一个`functionResponse`对象。这个对象表明：“这是你刚才要求调用的`read_file`工具的返回结果”。
    *   然后，系统会将这个`functionResponse`对象追加到对话历史中，并**再次向大模型发起请求**。

2.  **第二步：由大模型“翻译”结果并生成最终回答**
    *   此时，大模型拥有了最完整的上下文信息，包括：
        *   用户的原始问题。
        *   它自己决定要调用哪个工具（`functionCall`）。
        *   这个工具的实际执行结果（`functionResponse`）。
    *   基于这些完整的信息，大模型就能够“理解”工具返回结果的含义，并**生成一段通顺、流畅、且针对用户原始问题的最终回答**。例如，它不会直接把整个文件内容丢给用户，而是可能会说：“好的，文件`file.txt`从第10行开始的内容如下：...”。如果工具返回错误，它也能人性化地解释错误：“抱歉，读取文件失败了，因为它不存在。”

这个“提问 -> 模型决策 -> 系统执行 -> 结果反馈 -> 模型总结”的循环，是Gemini代理能够与工具无缝协作，并提供高质量、智能化回答的核心机制。
